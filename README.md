<h1 align="center">ğŸš€ Optimizing a Dynamic Trajectory</h1>

<p align="center">
  <i>AI Research & Development Assignment</i><br>
  <b>Author:</b> Prathikha<br>

</p>

<p align="center">
  <!-- Shields.io Badges for Technologies Used -->
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python">
  <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy">
  <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas">
  <img src="https://img.shields.io/badge/matplotlib-11557c?style=for-the-badge&logo=matplotlib&logoColor=white" alt="Matplotlib">
  <img src="https://img.shields.io/badge/scipy-8CA3ED?style=for-the-badge&logo=scipy&logoColor=white" alt="SciPy">
</p>

---
##  Project Overview

This repository presents a comprehensive solution to a **parametric curve fitting** problem modeling observed `(x, y)` data points with a nonlinear parametric equation and identifying optimal parameters that minimize the **L1 distance** (Manhattan distance) between the predicted and observed data.

The project combines **numerical optimization**, **parametric modeling**, and **data visualization** to demonstrate a research-oriented approach to real-world nonlinear curve fitting.

---

## ğŸ¯ Problem Statement

Given a dataset `xy_data.csv` containing `x` and `y` coordinates, the objective is to find the optimal values for three unknown parameters: `theta`, `M`, and `X`. These parameters define a parametric curve using the following equations:

**x(t) = t * cos(theta) - exp(M * |t|) * sin(0.3 * t) * sin(theta) + X**

**y(t) = 42 + t * sin(theta) + exp(M * |t|) * sin(0.3 * t) * cos(theta)**


The goal is to minimize the L1 distance (Manhattan distance) between the observed data points and the points generated by the parametric equations.


---

## Key Features & Technologies

- **Numerical Optimization:** Utilizes `scipy.optimize.differential_evolution` for global optimization, ensuring a robust search for the optimal parameters across a defined parameter space.
- **L1 Distance Metric:** Minimizes the sum of absolute differences â€” more robust to outliers than L2 norm.  
- **Parametric Curve Modeling:** Implements nonlinear equations with trigonometric and exponential components.  
- **Data Visualization:** Leverages `matplotlib` to visually compare the observed data points with the fitted parametric curve, providing an intuitive understanding of the fitting accuracy.
- **Reproducibility:** Incorporates `np.random.seed(42)` and `random.seed(42)` to ensure consistent results on every run, a crucial aspect for scientific computing.


---

##  ğŸ§© Step-by-Step Process

### 1ï¸âƒ£ Data Loading
- The dataset `xy_data.csv` is read using **Pandas**, and `x_data`, `y_data` arrays are extracted.
- A corresponding `t_range` (6 â†’ 60) is assumed for sequential sampling.

### 2ï¸âƒ£ Defining the Model
Two parametric equations (`parametric_x` and `parametric_y`) are implemented.  
- `theta` is converted to radians (`np.deg2rad`) for trigonometric computations.  
- The exponential term adds nonlinear scaling with respect to `M` and `t`.

### 3ï¸âƒ£ Defining the Objective Function
- The **error function** computes the total **L1 distance** between observed and predicted points:
  ```python
  L1 = np.sum(np.abs(x_pred - x_data)) + np.sum(np.abs(y_pred - y_data))
  ```
- This function is minimized during optimization.

### 4ï¸âƒ£ Setting Parameter Bounds
| Parameter | Description | Range |
|------------|--------------|--------|
| `theta` | Angle of rotation (in degrees) | 0 â€“ 50 |
| `M` | Exponential growth/decay factor | -0.05 â€“ 0.05 |
| `X` | Horizontal shift | 0 â€“ 100 |

### 5ï¸âƒ£ Global Optimization with Differential Evolution
- `scipy.optimize.differential_evolution` is used for robust global search.
- It works well with **non-convex, multi-modal** objective surfaces.
- Seeded with `42` for reproducibility.

### 6ï¸âƒ£ Results Extraction
After optimization:
- Extract best-fit parameters:
  ```
  Optimal Theta: 27.9990 degrees
  Optimal M: 0.0211
  Optimal X: 54.2703
  Minimum L1 Error:Â 37873.4825
  ```
- Results are saved in `fit_results.txt`.

### 7ï¸âƒ£ Visualization
A smooth fitted curve is generated and compared to observed data:
- **ğŸ”´ Red Points:** Observed Data  
- **ğŸ”µ Blue Curve:** Fitted Model  

Output visualization  
![Parametric Fit Result](parametric_fit_result.png)

### ğŸ¯ Interactive Visualization  
Explore the optimized trajectory interactively on Desmos:  
[ğŸ”— Open Live Graph on Desmos](https://www.desmos.com/calculator/zt1hdklypi)



---

## ğŸ’» Installation & Usage

### 1. Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/parametric-curve-fitting.git
cd parametric-curve-fitting
```
### 2. Set Up Environment
```bash
pip install numpy pandas scipy matplotlib
```

### 3. Run the Notebook
Open the Jupyter Notebook and run all the cells in order
```bash
jupyter notebook
```

### 4. Outputs
- ğŸ“„ `fit_results.txt` â†’ numerical results  
- ğŸ–¼ï¸ `parametric_fit_result.png` â†’ visualization  
- ğŸ§¾ Console â†’ optimized parameters + minimum L1 error    

---

## ğŸ§¾ Evaluation Criteria & My Approach

| **Criterion** | **Implementation / Explanation** |
|----------------|----------------------------------|
| **L1 Distance Accuracy (100 pts)** | Used L1 norm for robustness; ensures minimal deviation even with outliers. |
| **Process Explanation (80 pts)** | Step-by-step documentation of mathematical reasoning and computational pipeline. |
| **Code Quality (50 pts)** | Structured, reproducible, and well-documented code with automated output saving. |

---

## ğŸ§   Conceptual Insights

- **Parametric Modeling:** Enables flexible transformations like scaling, rotation, and translation.  
- **L1 vs L2:** L1 provides stability and resistance to large residuals.  
- **Global Optimization:** Differential Evolution avoids local minima traps that plague gradient-based methods.  
- **Visualization:** Critical to validate and interpret fitting quality intuitively.

---

## ğŸ“ Folder Structure

```
ğŸ“ parametric-curve-fitting
â”‚
â”œâ”€â”€ xy_data.csv                  # Input dataset
â”œâ”€â”€ parametric_fit.py            # Main script
â”œâ”€â”€ fit_results.txt              # Optimization results
â”œâ”€â”€ parametric_fit_result.png    # Output visualization
â””â”€â”€ README.md                    # Documentation
```

---

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

In case of any queries, please leave a message or contact me via the email provided in my profile.

---

<p align="center">
â­ <strong>Star this repository if you found it helpful!</strong>
</p>



